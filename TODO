[Done] Add download folder specification in config file
[Done] Add category and page number specification in config file
[Done] (Use FastAPI and Uvicorn to run Python API server, relatively high performance) Decide whether to have a seperate program to serve public api or make the crawler itself to serve public api (might not have a good performance), or just no public api at all

Add image quality specification in config file (original, large, medium)
Add whether to download all pages of a illustration or just the first page, or just ignore the illustration if it has multiple pages
Add store mode that only stores image info (id, title, author, tags, url) in database (sqlite, or other sql/nosql serverless database)
Decide whether to make the crawler runs freshly and periodically (i.e. using a crontab to update images) or make the crawler stays in background and runs periodically (specify fetch time interval in config)
